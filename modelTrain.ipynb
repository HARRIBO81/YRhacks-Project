{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelTrain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fqgn5Ogg0VQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed12b69-21cf-4066-b4b7-3011dc082732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/YR Hacks ML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DajSoqNY5WDs",
        "outputId": "3627a215-33d5-494b-eb02-eaefc1f883a3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/YR Hacks ML\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpcZWio5Xm3u",
        "outputId": "fc97358e-71b1-49ab-d774-f5e2195f01a9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtj-oUSr5n9K",
        "outputId": "1a831870-55e0-46f4-e7df-fea083fdcc98"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the data sets for training**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ClRmY92R6vC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, os\n",
        "dataSet = \"/content/drive/MyDrive/YR Hacks ML/data\"\n",
        "types = os.listdir(dataSet)\n",
        "typeNames = [i for i in range(len(types))]\n",
        "labelDict = dict(zip(types,typeNames))\n",
        "\n",
        "print(labelDict)\n",
        "print(types)\n",
        "print(typeNames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5EgdsCA5vkT",
        "outputId": "ed9df017-fe72-4747-908a-b0ed2dc1aea4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'melanoma': 0, 'basal cell carcinoma': 1, 'squamous cell carcinoma': 2}\n",
            "['melanoma', 'basal cell carcinoma', 'squamous cell carcinoma']\n",
            "[0, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imageSize=100\n",
        "data=[]\n",
        "target=[]\n",
        "\n",
        "for i in types:\n",
        "  folderPath = os.path.join(dataSet, i)\n",
        "  imageNames = os.listdir(folderPath)\n",
        "\n",
        "  for imageName in imageNames:\n",
        "      imagePath = os.path.join(folderPath,imageName)\n",
        "      image=cv2.imread(imagePath)\n",
        "        \n",
        "      try:  \n",
        "          resizedImage=cv2.resize(image,(imageSize,imageSize))\n",
        "          #resizing the image  into 100x100, since we need a fixed common size for all the images in the dataset\n",
        "          data.append(resizedImage)\n",
        "          target.append(labelDict[i])\n",
        "          #appending the image and the label(categorized) into the list (dataset)\n",
        "      except Exception as e:\n",
        "          print('Exception:',e)\n",
        "          #if any exception rasied, the exception will be printed here. And pass to the next image\n"
      ],
      "metadata": {
        "id": "lFiFnjvK65Ck"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rescaling/Reshaping training data***"
      ],
      "metadata": {
        "id": "d75cwyFJ-F-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "data = np.array(data)/255.0\n",
        "data = np.reshape(data, (data.shape[0], imageSize,imageSize,3))\n",
        "target = np.array(target)\n",
        "updatedTarget = np_utils.to_categorical(target)"
      ],
      "metadata": {
        "id": "mGgqbQlY-P7Z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updatedTarget.shape #Check the total number of training images, and number of categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e5ZixPAAejC",
        "outputId": "3258623e-46f9-41ae-99f5-b662f8ec1ab6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1043, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN Model***"
      ],
      "metadata": {
        "id": "kfdux0ARAoG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape #955 images, 100x100, 3 categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1-czfRpArZw",
        "outputId": "e83fc208-249b-4769-f982-ee248e359f90"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1043, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llbnFju-AwrP",
        "outputId": "36431085-e6f7-4da7-e883-ca94f06c9372"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The first CNN layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model.add(Conv2D(100,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The second convolution layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "#Flatten layer to stack the output convolutions from second convolution layer\n",
        "model.add(Dense(50,activation='relu'))\n",
        "#Dense layer of 64 neurons\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "#The Final layer with two outputs for two categories\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "lHqMG0bRCCAj"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG-rYdL1CH_w",
        "outputId": "f3a90727-d8cf-40d4-e512-8e62388b13c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 98, 98, 200)       5600      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 98, 98, 200)       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 49, 49, 200)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 47, 47, 100)       180100    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 47, 47, 100)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 23, 23, 100)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 52900)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 52900)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                2645050   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,830,852\n",
            "Trainable params: 2,830,852\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting into training (70%), testing (10%) and validation (20%)**"
      ],
      "metadata": {
        "id": "xJxTbAaEVTeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data,test_data,train_target,test_target = train_test_split(data,updatedTarget,test_size=0.1)"
      ],
      "metadata": {
        "id": "75VI-0sjCMUp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMaUYeY6V391",
        "outputId": "70836310-1821-4bcf-89fb-bf67635dde15"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(938, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHvADXPWWKmm",
        "outputId": "7baa697c-1bc4-4185-c1fc-161b94348b45"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(938, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_data,train_target,epochs=200,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "aKCl6NfBWNy-",
        "outputId": "62519ac0-ae03-4f5d-fdac-ae3c09d2e800"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-d0608b58ec3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1790, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 3) and (None, 2) are incompatible\n"
          ]
        }
      ]
    }
  ]
}